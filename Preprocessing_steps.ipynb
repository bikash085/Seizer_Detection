{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ddc5a6",
   "metadata": {},
   "source": [
    "# Preprocessing for seizure prediction data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53836783",
   "metadata": {},
   "source": [
    "## Making 5 columns on the basis of sampling freqency of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8dc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_input_file(input_file, output_file, window_size=5):\n",
    "    # Read the input file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Create a dictionary to store lists of values for each column\n",
    "    output_data = {}\n",
    "\n",
    "    # Initialize the tqdm progress bar\n",
    "    total_iterations = len(df) - window_size + 1\n",
    "    pbar = tqdm(total=total_iterations, desc='Processing')\n",
    "\n",
    "    # Iterate over each rolling window of 5 rows\n",
    "    for i in range(len(df) - window_size + 1):\n",
    "        # Iterate over each input column\n",
    "        for col in df.columns:\n",
    "            # Extract values from each row in the window\n",
    "            values = df[col].iloc[i:i+window_size].tolist()\n",
    "\n",
    "            # Create new columns in the output dictionary\n",
    "            for j, value in enumerate(values, start=1):\n",
    "                col_name = f'{col}_{j}'\n",
    "                if col_name not in output_data:\n",
    "                    output_data[col_name] = []\n",
    "                output_data[col_name].append(value)\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    output_df = pd.DataFrame(output_data)\n",
    "\n",
    "    # Save the output DataFrame to a new CSV file\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Close the progress bar\n",
    "    pbar.close()\n",
    "\n",
    "# Provide the input and output file names\n",
    "input_file = 'C:/Users/USER/Desktop/4th_sem/DataSet/chbmit_ictal_23channels_data.csv'  # Replace with your input file path\n",
    "output_file = 'C:/Users/USER/Desktop/4th_sem/Processed_DataSet_1/chbmit_ictal_23channels_data_making_5_columns.csv'  # Replace with your desired output file path\n",
    "\n",
    "# Call the function to process the input file and generate the output file\n",
    "process_input_file(input_file, output_file)\n",
    "\n",
    "print(f\"Processing complete. Output saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f7cfcb",
   "metadata": {},
   "source": [
    "## Multipliying the value with 2^30 to so fit them our desired length when converted to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def multiply_values_by_power_and_save(file_path, output_file, power):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Multiply each value by 2^power\n",
    "    result_df = df * 2**power\n",
    "\n",
    "    # Save the result to a new CSV file\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Provide the input and output file names\n",
    "input_file = 'C:/Users/USER/Desktop/4th_sem/Processed_DataSet_1/chbmit_ictal_23channels_data_making_5_columns.csv'  # Replace with the path to your CSV file\n",
    "output_file = 'C:/Users/USER/Desktop/4th_sem/Processed_Dataset_2/ictal_2^30.csv'  # Replace with the desired output file name\n",
    "\n",
    "# Specify the power for multiplication (e.g., 30 for 2^30)\n",
    "power = 30\n",
    "\n",
    "# Call the function to multiply values and save to a new file\n",
    "multiply_values_by_power_and_save(input_file, output_file, power)\n",
    "\n",
    "print(f\"Values multiplied and saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2eb23",
   "metadata": {},
   "source": [
    "## Considering the integer part of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_integer_part(input_file, output_file):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    total_cells = df.size\n",
    "    progress_bar = tqdm(total=total_cells, desc='Processing')\n",
    "\n",
    "    # Extract the integer part from each value\n",
    "    df_integer = df.applymap(lambda x: int(x) if pd.notna(x) else x)\n",
    "    progress_bar.update(total_cells)\n",
    "\n",
    "    # Save the DataFrame with only integer parts to a new CSV file\n",
    "    df_integer.to_csv(output_file, index=False)\n",
    "\n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "# Provide the file path for the input CSV file and the desired output file\n",
    "input_file = 'C:/Users/USER/Desktop/4th_sem/Processed_Dataset_2/ictal_2^30.csv'  # Replace with the path to your CSV file\n",
    "output_file = 'C:/Users/USER/Desktop/4th_sem/Processed_dataset_3/ictal_integer.csv'  # Replace with the desired output file path\n",
    "\n",
    "# Call the function to extract integer parts and create a new CSV file\n",
    "extract_integer_part(input_file, output_file)\n",
    "\n",
    "# Print a message indicating the completion of the process\n",
    "print(f\"Integer parts saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389325b",
   "metadata": {},
   "source": [
    "## Converting them to binary representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140233b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import struct\n",
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def float_to_binary(value):\n",
    "    # Convert a floating-point number to IEEE 754 binary representation\n",
    "    if math.isnan(value):\n",
    "        return '0' * 31  # Special case for NaN\n",
    "    elif value == 0.0:\n",
    "        return '0' * 31  # Special case for zero\n",
    "    else:\n",
    "        # Extract sign, exponent, and fraction parts\n",
    "        sign = 0 if value >= 0 else 1\n",
    "        value = abs(value)\n",
    "        exponent = 15  # Set a common exponent value for all numbers\n",
    "        fraction = value / (2 ** exponent)\n",
    "\n",
    "        # Adjust the fraction to ensure a total of 22 binary digits\n",
    "        fraction_bits = bin(int(fraction * (2 ** 22)))[2:].zfill(22)\n",
    "\n",
    "        # Convert to IEEE 754 binary representation\n",
    "        return str(sign) + bin(exponent)[2:].zfill(5) + fraction_bits\n",
    "\n",
    "def convert_to_binary(input_file, output_file, rows_to_process=5000):\n",
    "    df = pd.read_csv(input_file, nrows=rows_to_process)\n",
    "    total_rows, total_cols = df.shape\n",
    "\n",
    "    binary_df = pd.DataFrame()\n",
    "\n",
    "    for row_index in tqdm(range(rows_to_process), desc='Converting', total=rows_to_process):\n",
    "        for col_index in range(total_cols):\n",
    "            cell_value = df.iloc[row_index, col_index]\n",
    "            binary_value = float_to_binary(cell_value)\n",
    "\n",
    "            # Append the binary representation to the DataFrame\n",
    "            binary_df.at[row_index, col_index] = binary_value\n",
    "\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    binary_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Provide the file path for conversion and the desired output file\n",
    "input_file = 'C:/Users/USER/Desktop/4th_sem/Processed_Dataset_2/preictal_2^30.csv'  # Replace with the path to your CSV file\n",
    "output_file = 'C:/Users/USER/Desktop/4th_sem/Processed_dataset_3/binary_output_3rd.csv'  # Replace with the desired output file\n",
    "\n",
    "# Specify the number of rows to process (e.g., 5000)\n",
    "rows_to_process = 5000\n",
    "\n",
    "# Call the function to convert each cell value and save the result to a single CSV file\n",
    "convert_to_binary(input_file, output_file, rows_to_process)\n",
    "\n",
    "# Print a message indicating the completion of the process\n",
    "print(f\"Binary representations for the first {rows_to_process} rows saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146dbd8",
   "metadata": {},
   "source": [
    "## Representing in 2's complement from for handling negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def convert_to_24_bit_signed(binary_str):\n",
    "    \"\"\"Converts a binary string to 24-bit signed representation.\"\"\"\n",
    "    if binary_str.startswith(\"-\"):\n",
    "        # Negative number\n",
    "        binary_str = binary_str[1:]  # Remove the \"-\" sign\n",
    "        inverted_bits = ''.join('1' if bit == '0' else '0' for bit in binary_str)\n",
    "        twos_complement = bin(int(inverted_bits, 2) + 1)[2:]\n",
    "        padded_binary = f\"1{twos_complement:0>23}\"  # Pad with \"1\" for negative numbers\n",
    "        _binary = padded_binary[-24:]\n",
    "    else:\n",
    "        # Positive number\n",
    "        padded_binary = f\"0{binary_str:0>23}\"  # Pad with \"0\" for positive numbers\n",
    "        _binary = padded_binary[-24:]\n",
    "\n",
    "    return _binary\n",
    "\n",
    "def main():\n",
    "    input_file = \"C:/Users/USER/Desktop/4th_sem/Processed_Dataset_4/ictal_binary.csv\"\n",
    "    output_file = \"C:/Users/USER/Desktop/4th_sem/Processed_Dataset_5/ictal_2s_binary.csv\"\n",
    "\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        header = next(reader)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for row in reader:\n",
    "            converted_row = [convert_to_24_bit_signed(value) for value in row]\n",
    "            writer.writerow(converted_row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016dfbe6",
   "metadata": {},
   "source": [
    "## Representing in six bit codon's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_24_bits(input_string):\n",
    "    if len(input_string) != 24:\n",
    "        raise ValueError(\"Input string must be 24 bits long\")\n",
    "\n",
    "    # Using list comprehension to create a list of 6-bit parts\n",
    "    parts = [input_string[i:i + 6] for i in range(0, len(input_string), 6)]\n",
    "\n",
    "    return parts\n",
    "\n",
    "def ensure_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def process_csv(input_file, output_directory):\n",
    "    # Load your CSV file into a DataFrame with dtype='object'\n",
    "    df = pd.read_csv(input_file, dtype='object')\n",
    "\n",
    "    # Create new columns based on the modified split_24_bits function\n",
    "    new_columns = {}\n",
    "    total_columns = len(df.columns)\n",
    "\n",
    "    for column in tqdm(df.columns, desc=\"Processing Columns\"):\n",
    "        # Apply the modified function to each element in the column\n",
    "        split_values = df[column].apply(split_24_bits)\n",
    "\n",
    "        # Create new columns for each item in the split values list\n",
    "        for i in range(4):\n",
    "            new_columns[f\"{column}_{i}\"] = [item[i] for item in split_values]\n",
    "\n",
    "    # Create a DataFrame with the new columns, specifying dtype='object'\n",
    "    new_df = pd.DataFrame(new_columns, dtype='object')\n",
    "\n",
    "    # Format each cell value to preserve leading zeros\n",
    "    new_df = new_df.applymap(lambda x: f'{x:06}')\n",
    "\n",
    "    # Get the input file name without extension\n",
    "    input_file_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "\n",
    "    # Customize the output file name with a different extension (e.g., '.xlsx')\n",
    "    ensure_directory(output_directory)\n",
    "    output_file = os.path.join(output_directory, f\"{input_file_name}_split_modified.xlsx\")\n",
    "\n",
    "    # Save the modified DataFrame to a new Excel file\n",
    "    new_df.to_excel(output_file, index=False, engine='xlsxwriter')\n",
    "\n",
    "    print(\"Task completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"/content/drive/MyDrive/Seizer Detection/Process_Dataset_5/prectical_2s_binary_5000.csv\"  # Replace with the actual input file path\n",
    "    output_directory = \"/content/drive/MyDrive/Seizer Detection/Process_Dataset_6\"  # Specify the output directory\n",
    "    process_csv(input_file, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b96ee5",
   "metadata": {},
   "source": [
    "## Making 8-bits by adding two zeros(00). Previously used 8 bit formula to convert amino acid. For using that formula need to convert them into 8-bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def ensure_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def pad_to_8_bits(binary_str):\n",
    "    \"\"\"Pad binary string to ensure it is 8 bits long.\"\"\"\n",
    "    return f'{binary_str:0>8}'\n",
    "\n",
    "def convert_to_8_bits(binary_str):\n",
    "    \"\"\"Converts a binary string to 8-bit representation.\"\"\"\n",
    "    return pad_to_8_bits(binary_str + '00')  # Add two '0's at the end\n",
    "\n",
    "def main():\n",
    "    input_file = \"C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_6/ictal_processed/ictal_2s_binary_split_modified.csv\"\n",
    "    output_file = \"C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_7/ictal_processed/ictal_8_bit_codons.csv\"\n",
    "\n",
    "    ensure_directory(os.path.dirname(output_file))\n",
    "\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        next(reader)  # Skip the first row containing column names\n",
    "        next(reader)  # Skip the second row\n",
    "\n",
    "        total_rows = sum(1 for _ in reader)  # Count total rows for the progress bar\n",
    "        infile.seek(0)  # Reset file pointer to read from the beginning\n",
    "\n",
    "        for row in tqdm(reader, total=total_rows, desc=\"Processing Rows\"):\n",
    "            converted_row = [convert_to_8_bits(value) for value in row]\n",
    "            writer.writerow(converted_row)\n",
    "\n",
    "    print(\"Task completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01ee26",
   "metadata": {},
   "source": [
    "## Converting to Decimal integers for applying ammino acid formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Replace 'your_file_path.csv' with the actual file path\n",
    "file_path = \"C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_7/ictal_processed/ictal_8_bit_codons.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame, skipping the first row\n",
    "df = pd.read_csv(file_path, dtype='object', skiprows=0)\n",
    "\n",
    "# Function to convert binary to decimal\n",
    "def binary_to_decimal(binary_str):\n",
    "    return int(binary_str, 2)\n",
    "\n",
    "# Create a new DataFrame for the decimal values\n",
    "df_decimal = pd.DataFrame()\n",
    "\n",
    "# Use tqdm for a progress bar\n",
    "for column in tqdm(df.columns, desc=\"Converting to Decimal\"):\n",
    "    # Convert binary to decimal and add to the new DataFrame\n",
    "    df_decimal[column] = df[column].apply(binary_to_decimal)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "output_csv_path = \"C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_8/ictal_processed/ictal_integer_codons.csv\"\n",
    "df_decimal.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Decimal values saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1892bf",
   "metadata": {},
   "source": [
    "## Mapping to ammino acid sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prot(p):\n",
    "    ch = 0\n",
    "    if p == 0 or p == 4:\n",
    "        ch = 1\n",
    "    elif p == 12 or p == 8:\n",
    "        ch = 2\n",
    "    elif 16 <= p <= 28:\n",
    "        ch = 3\n",
    "    elif p == 48 or p == 52:\n",
    "        ch = 4\n",
    "    elif p in [56, 60, 44]:\n",
    "        ch = 23\n",
    "    elif p in [32, 36]:\n",
    "        ch = 5\n",
    "    elif p == 40:\n",
    "        ch = 6\n",
    "    elif 64 <= p <= 76:\n",
    "        ch = 7\n",
    "    elif 80 <= p <= 92:\n",
    "        ch = 8\n",
    "    elif p == 112 or p == 116:\n",
    "        ch = 9\n",
    "    elif p == 124 or p == 120:\n",
    "        ch = 10\n",
    "    elif 96 <= p <= 108:\n",
    "        ch = 11\n",
    "    elif p in [192, 196, 204]:\n",
    "        ch = 12\n",
    "    elif p == 200:\n",
    "        ch = 23\n",
    "    elif 208 <= p <= 220:\n",
    "        ch = 13\n",
    "    elif p == 240 or p == 244:\n",
    "        ch = 14\n",
    "    elif p in [248, 252]:\n",
    "        ch = 15\n",
    "    elif p == 224 or p == 228:\n",
    "        ch = 16\n",
    "    elif p == 232 or p == 236:\n",
    "        ch = 17\n",
    "    elif 128 <= p <= 140:\n",
    "        ch = 18\n",
    "    elif 144 <= p <= 156:\n",
    "        ch = 19\n",
    "    elif p == 176 or p == 180:\n",
    "        ch = 20\n",
    "    elif p == 184 or p == 188:\n",
    "        ch = 21\n",
    "    elif 160 <= p <= 172:\n",
    "        ch = 22\n",
    "    return ch\n",
    "\n",
    "def map_values_and_save(input_file, output_file):\n",
    "    try:\n",
    "        # Read CSV file using pandas\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        # Count total number of elements for progress bar\n",
    "        total_elements = df.size\n",
    "\n",
    "        # Apply the prot function to each value in the DataFrame with tqdm progress bar\n",
    "        tqdm.pandas(desc=\"Mapping progress\")\n",
    "        df_mapped = df.progress_applymap(prot)\n",
    "\n",
    "        # Save the results to a new CSV file\n",
    "        df_mapped.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Mapping completed. Results saved to {output_file}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please provide a valid file path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'input.csv' and 'output.csv' with your file paths\n",
    "input_file_path = \"C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_8/ictal_processed/ictal_integer_codons.csv\"\n",
    "output_file_path = \"C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_9/ictal_aminoacid/ictal_aminoacid_sequence.csv\"\n",
    "\n",
    "map_values_and_save(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c98131",
   "metadata": {},
   "source": [
    "## Assigning Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a61ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_9/prectal_aminoacid/prectical_aminoacid_sequence.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df['class'] = '0'\n",
    "output_file_path = 'C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_10/prectial/prectial_data.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Class column added and file saved at: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c93b66",
   "metadata": {},
   "source": [
    "## Merge both preictal and ictal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36195c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "preictal_file_path = 'C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_10/prectial/prectial_data.csv'\n",
    "ictal_file_path = 'C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_10/ictal/ictal_data.csv'\n",
    "output_file_path = 'C:/Users/Administrator/Desktop/khalid/seizer Detection/Processed_Dataset_11/merge_preictal_ictal.csv'\n",
    "\n",
    "print(\"Loading Preictal data...\")\n",
    "preictal_df = pd.read_csv(preictal_file_path)\n",
    "\n",
    "print(\"Loading Ictal data...\")\n",
    "ictal_df = pd.read_csv(ictal_file_path)\n",
    "\n",
    "print(\"Combining datasets...\")\n",
    "combined_df = pd.concat([preictal_df, ictal_df], axis=0).progress_apply(lambda x: x)\n",
    "\n",
    "print(\"Shuffling combined dataset...\")\n",
    "shuffled_df = shuffle(combined_df, random_state=42)\n",
    "\n",
    "shuffled_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Combined and shuffled dataset saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
